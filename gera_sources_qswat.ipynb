{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f8e43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm   # Acrescentado tqdm para barra de progresso\n",
    "from calendar import monthrange # Cria uma lista de tuplas (mês, dia) apenas para datas válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv(arquivo_csv, cod_estacao, codificacao='latin1'):\n",
    "    \"\"\"Lê o csv e converte a coluna de data para datetime.\n",
    "    Vazões totais = latin1\n",
    "    FLU_Series_ANA = utf-8\n",
    "    \"\"\"\n",
    "    parse_dates = None\n",
    "\n",
    "    # Detectar o nome correto da coluna de data (pode vir com aspas ou não)\n",
    "    # Apenas lê a primeira linha para inspecionar os nomes das colunas\n",
    "    if arquivo_csv.endswith('.csv'):\n",
    "        colunas = pd.read_csv(arquivo_csv, encoding=codificacao, engine='python', nrows=0).columns\n",
    "    elif arquivo_csv.endswith('.txt'):\n",
    "        colunas = pd.read_csv(arquivo_csv, sep='\\\\t', encoding=codificacao, engine='python', nrows=0).columns\n",
    "    else:\n",
    "        raise ValueError(\"Arquivo deve ser .csv ou .txt\")\n",
    "    \n",
    "    # Normalizar nomes para comparar\n",
    "    colunas_norm = [col.strip().replace('\"', '') for col in colunas]\n",
    "    if \"Data\" in colunas_norm:\n",
    "        parse_dates = [colunas[list(colunas_norm).index(\"Data\")]]\n",
    "\n",
    "    # Agora lê o arquivo já com parse_dates se detectou a coluna\n",
    "    if arquivo_csv.endswith('.csv'):\n",
    "        df = pd.read_csv(arquivo_csv, engine='python', parse_dates=parse_dates)\n",
    "    elif arquivo_csv.endswith('.txt'):\n",
    "        df = pd.read_csv(arquivo_csv, sep='\\\\t', encoding='latin1', engine='python', parse_dates=parse_dates)\n",
    "    \n",
    "    # Corrigir nomes das colunas para remover aspas e facilitar o acesso\n",
    "    df.columns = [col.strip().replace('\"', '') for col in df.columns]\n",
    "        \n",
    "    if \"Cod.estacao\" in df.columns:\n",
    "        df.rename(columns={\"Cod.estacao\": \"cod_estacao\"}, inplace=True)\n",
    "    \n",
    "    if \"Cod_estacao\" in df.columns:\n",
    "        df.rename(columns={\"Cod_estacao\": \"cod_estacao\"}, inplace=True)\n",
    "        \n",
    "    if \"cod_estacao\" not in df.columns:\n",
    "        raise ValueError(\"A coluna 'cod_estacao' não foi encontrada no arquivo.\")\n",
    "    \n",
    "    df = df[df[\"cod_estacao\"] == cod_estacao]\n",
    "    \n",
    "    # Corrigir coluna de data: remover aspas e converter para datetime\n",
    "    if \"Data\" in df.columns:\n",
    "        df[\"Data\"] = df[\"Data\"].astype(str).str.replace('\"', '').str.strip()\n",
    "        df[\"Data\"] = pd.to_datetime(df[\"Data\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b473862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dia_mes_ano(df):\n",
    "    df['Data'] = pd.to_datetime(df['Data'], format='%Y-%m-%d', errors='coerce')\n",
    "    df['Dia'] = df['Data'].dt.day\n",
    "    df['Mes'] = df['Data'].dt.month\n",
    "    df['Ano'] = df['Data'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0596e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_anos_incompletos(df):\n",
    "    # Filtra anos que não possuem todos os meses\n",
    "    anos_completos = df['Ano'].value_counts()[df['Ano'].value_counts() >= 365].index\n",
    "    return df[df['Ano'].isin(anos_completos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d14cd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_vazao_media_diaria_por_mes(df):\n",
    "    \n",
    "    resultados = []\n",
    "    for m in range(1, 13):\n",
    "        dias_no_mes = monthrange(2000, m)[1]  # 2000 é um ano bissexto, mas só importa o número de dias\n",
    "        for d in range(1, dias_no_mes + 1):\n",
    "            df_filtro = df[(df['Mes'] == m) & (df['Dia'] == d)]\n",
    "            media = round(df_filtro['Vazao'].mean(), 2)\n",
    "            resultados.append({'Mes': m, 'Dia': d, 'Vazao': media})\n",
    "\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c32d8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_lista_anos_serie_indicar_bissexto(ano_inicial, ano_final):\n",
    "    \n",
    "    # Criar lista de anos da série\n",
    "    lista_anos_serie = list(range(ano_inicial, ano_final + 1))\n",
    "    \n",
    "    # Listar anos bissextos \n",
    "    anos_bissextos = [ano for ano in lista_anos_serie if (ano % 4 == 0 and ano % 100 != 0) or (ano % 400 == 0)]\n",
    "\n",
    "    # df \n",
    "    df_anos = pd.DataFrame({\n",
    "    'Ano': lista_anos_serie,\n",
    "    'Bissexto': [1 if ano in anos_bissextos else 0 for ano in lista_anos_serie]\n",
    "    })\n",
    "    return df_anos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d990822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_arquivo_estacao_virtual_txt(id, nome, lat, long, elevation, nome_arquivo):\n",
    "    id = id\n",
    "    name = nome\n",
    "    lat = lat\n",
    "    long = long\n",
    "    elevation = elevation\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "            'ID': [id],\n",
    "            'NAME': [name],\n",
    "            'LAT': [lat],\n",
    "            'LONG': [long],\n",
    "            'ELEVATION': [elevation]\n",
    "        })\n",
    "        \n",
    "        # Criar o a rquivo de saída\n",
    "    with open(f\"{os.path.join(os.getcwd(), nome_arquivo)}.txt\", 'w') as f:\n",
    "        f.write(\"ID,NAME,LAT,LONG,ELEVATION\\n\")\n",
    "        # Se tiver mais de uma linha, escrever todas\n",
    "        if len(df) > 1:\n",
    "            for index, row in df.iterrows():\n",
    "                    f.write(f\"{row['ID']},{row['NAME']},{row['LAT']},{row['LONG']},{row['ELEVATION']}\\n\")\n",
    "        else:\n",
    "            # Se tiver apenas uma linha, escrever apenas uma vez\n",
    "            f.write(f\"{df['ID'][0]},{df['NAME'][0]},{df['LAT'][0]},{df['LONG'][0]},{df['ELEVATION'][0]}\\n\")\n",
    "        print(f\"Arquivo '{nome_arquivo}.txt' criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45d76168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_arquivo_dados_estacao_virtual_txt(df, var_mes, var_ano, var_vazao, nome_arquivo, subbacia ):\n",
    "    \"\"\"Cria um arquivo de dados climáticos formatado.\"\"\"\n",
    "                \n",
    "    with open(f\"{nome_arquivo}_{subbacia}.txt\", 'w') as f:\n",
    "        f.write('\"Month\",\"Year\",\"Flomon\",\"Sedmon\",\"Orgnmon\",\"Orgpmon\",\"No3mon\",\"Nh3mon\",\"No2mon\",\"Minpmon\",\"Cbodmon\",\"Disoxmon\",\"Chlamon\",\"Solpstmon\",\"Srbpstmon\",\"Bactpmon\",\"Bactlpmon\",\"Cmtl1mon\",\"Cmtl2mon\",\"Cmtl3mon\"\\n')\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            mes = int(row[var_mes])\n",
    "            ano = int(row[var_ano])\n",
    "            vazao = round(row[var_vazao],3)\n",
    "            \n",
    "            f.write(f\"{mes},{ano},{vazao},0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000\\n\")\n",
    "        print(f\"Arquivo '{nome_arquivo}_{subbacia}' criado com sucesso.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dfdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando pipeline de precipitação...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  10%|█         | 1/10 [00:01<00:13,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60476155_62' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  20%|██        | 2/10 [00:03<00:12,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60476160_20' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  30%|███       | 3/10 [00:04<00:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60476170_0' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  40%|████      | 4/10 [00:06<00:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60479200_61' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  50%|█████     | 5/10 [00:08<00:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480000_65' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  60%|██████    | 6/10 [00:09<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480045_37' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  70%|███████   | 7/10 [00:11<00:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480055_23' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  80%|████████  | 8/10 [00:12<00:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480200_61' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações:  90%|█████████ | 9/10 [00:14<00:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480310_51' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando estações: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo '60480550_71' criado com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando pipeline de precipitação...\")\n",
    "media_diaria = False\n",
    "lista_cod_estacao = [60473000, 60471185, 60474000]\n",
    "subbacias = [40, 15, 34]\n",
    "arquivo_csv = \"FLU_Series_ANA.txt\"\n",
    "# lats = [-15.8094,-15.8186, -15.8186, -15.7956, -15.7925]\n",
    "# longs = [-47.7006,-47.705, -47.7047, -47.7844, -47.7647]\n",
    "# alts = [773,860,860,1000, 885.18]\n",
    "# nome_arquivo_est = \"vazao\"\n",
    "# for i, estacao, lat, long, alt in zip(range(len(lista_cod_estacao)), lista_cod_estacao, lats, longs, alts):\n",
    "#     criar_arquivo_estacao_virtual_txt(i + 1, f\"v{estacao}\", lat, long, alt, nome_arquivo_est)\n",
    "\n",
    "for estacao, subbacia in tqdm(zip(lista_cod_estacao, subbacias), total=len(lista_cod_estacao), desc=\"Processando estações\"):\n",
    "    df = ler_csv(arquivo_csv, estacao)\n",
    "    df = criar_dia_mes_ano(df)\n",
    "    df = filtrar_anos_incompletos(df)\n",
    "    \n",
    "    if media_diaria:\n",
    "        df = criar_vazao_media_diaria_por_mes(df)\n",
    "\n",
    "    df_anos = criar_lista_anos_serie_indicar_bissexto(1966, 2009)\n",
    "    \n",
    "    # Corrigir: manter como DataFrame com colunas 'Mes' e 'Vazao'\n",
    "    df_ano_normal = df[~((df['Mes'] == 2) & (df['Dia'] == 29))].groupby(['Mes'])['Vazao'].mean().round(3).reset_index()\n",
    "    df_ano_normal['Vazao'] = df_ano_normal['Vazao'] * 60 * 60 * 24\n",
    "    \n",
    "    df_ano_bissexto = df.groupby(['Mes'])['Vazao'].mean().round(3).reset_index()\n",
    "    df_ano_bissexto['Vazao'] = df_ano_bissexto['Vazao'] * 60 * 60 * 24\n",
    "    \n",
    "    # Criar um dataframe com os anos e os dados de vazão por mes\n",
    "    lista = []\n",
    "    for _, row in df_anos.iterrows():\n",
    "        ano = row['Ano']\n",
    "        bissexto = row['Bissexto']\n",
    "        if bissexto:\n",
    "            for _, mes_row in df_ano_bissexto.iterrows():\n",
    "                lista.append({'Ano': ano, 'Mes': int(mes_row['Mes']), 'Vazao': mes_row['Vazao']})\n",
    "        else:\n",
    "            for _, mes_row in df_ano_normal.iterrows():\n",
    "                lista.append({'Ano': ano, 'Mes': int(mes_row['Mes']), 'Vazao': mes_row['Vazao']})\n",
    "\n",
    "    df_serie_anos = pd.DataFrame(lista)\n",
    "\n",
    "    criar_arquivo_dados_estacao_virtual_txt(df_serie_anos, 'Mes', 'Ano', 'Vazao', estacao, subbacia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
